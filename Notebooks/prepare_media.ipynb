{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tator\n",
    "import panoptes_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_now():\n",
    "    return datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = os.getenv('ZOONIVERSE_USERNAME')\n",
    "password = os.getenv('ZOONIVERSE_PASSWORD')\n",
    "\n",
    "zoon_project_id = 21853\n",
    "\n",
    "try:\n",
    "    # Login to panoptes using username and password\n",
    "    panoptes_client.Panoptes.connect(username=username, password=password)\n",
    "    print(f\"NOTE: Authentication to Zooniverse successful for {username}\")\n",
    "except Exception as e:\n",
    "    raise Exception(f\"ERROR: Could not login to Panoptes for {username}\\n{e}\")\n",
    "\n",
    "try:\n",
    "    # Get access to the Zooniverse project given the provided credentials\n",
    "    project = panoptes_client.Project.find(id=zoon_project_id)\n",
    "    print(f\"NOTE: Connected to Zooniverse project '{project.title}' successfully\")\n",
    "except Exception as e:\n",
    "    raise Exception(f\"ERROR: Could not access project {zoon_project_id}.\\n{e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = os.getenv('TATOR_TOKEN')\n",
    "project_id = 70\n",
    "\n",
    "try:\n",
    "    # Get the TATOR api given the provided token\n",
    "    api = tator.get_api(host='https://cloud.tator.io', token=token)\n",
    "    # Get the correct type of localization for the project (bounding box, attributes)\n",
    "    tator_project_id = project_id\n",
    "    state_type_id = 288  # State Type (ROV)\n",
    "    print(f\"NOTE: Authentication to TATOR successful for {api.whoami().username}\")\n",
    "except Exception as e:\n",
    "    raise Exception(f\"ERROR: Could not obtain needed information from TATOR.\\n{e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Reduced Season N Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Extract the shapes for the workflow\n",
    "csv_path = \"../data/classification_csv/click-a-coral-classifications_season_n.csv\"\n",
    "csv_path = os.path.abspath(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Remove the private, ground truth workflow\n",
    "df = df[df['workflow_id'] != 26984]\n",
    "\n",
    "# Save Season 1\n",
    "season_1_df = df[(df['workflow_id'] == 25828) & (df['workflow_version'] == 355.143)]\n",
    "season_1_df.to_csv(csv_path.replace(\"season_n\", \"season_1\"), index=False)\n",
    "# Remove Season 1\n",
    "df = df[df['workflow_id'] != 25828]\n",
    "\n",
    "# Save Season 2\n",
    "season_2_df = df[(df['workflow_id'] == 26428) & (df['workflow_version'] == 16.18)]\n",
    "season_2_df.to_csv(csv_path.replace(\"season_n\", \"season_2\"), index=False)\n",
    "# Remove Season 2\n",
    "df = df[df['workflow_version'] > 16.18]\n",
    "\n",
    "# Save Season 3\n",
    "season_3_df = df[(df['workflow_id'] == 26428) & (df['workflow_version'] == 48.28)]\n",
    "season_3_df.to_csv(csv_path.replace(\"season_n\", \"season_3\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cac.from_zooniverse import ZooniverseProcessor\n",
    "\n",
    "# Extract args\n",
    "workflow_id = 25828\n",
    "version = 355.143\n",
    "\n",
    "output_dir = \"../data/reduced/Season_1\"\n",
    "output_dir = os.path.abspath(output_dir)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "csv_path = csv_path.replace(\"season_n\", \"season_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ZooniverseProcessor instance and process the data\n",
    "processor = ZooniverseProcessor(csv_path, output_dir, workflow_id, version)\n",
    "\n",
    "# Clean the classification csv, convert to a dataframe for creating training data\n",
    "df, path = processor.clean_csv_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move Zipped Curated to Reduced Season Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_ids = df['Media ID'].unique().astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_path = os.path.abspath(\"../data/curated\")\n",
    "\n",
    "for media_id in media_ids:\n",
    "    # Assert that the zip file exists\n",
    "    zip_path = os.path.join(curated_path, f\"{media_id}.zip\")\n",
    "    if not os.path.exists(zip_path):\n",
    "        raise Exception(f\"ERROR: Could not find zip file for media {media_id} at {zip_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_path = os.path.abspath(\"../data/reduced/Season_2/media\")\n",
    "os.makedirs(temp_path, exist_ok=True)\n",
    "\n",
    "for media_id in tqdm(media_ids, desc=\"Unzipping media files\"):\n",
    "    # Unzip the media\n",
    "    zip_path = os.path.join(curated_path, f\"{media_id}.zip\")\n",
    "    dst_path = os.path.join(temp_path, media_id)\n",
    "    \n",
    "    # Check if zip exists and destination doesn't exist yet\n",
    "    if not os.path.exists(zip_path):\n",
    "        raise Exception(f\"ERROR: Could not find zip file for media {media_id} at {zip_path}.\")\n",
    "        \n",
    "    if os.path.exists(dst_path):\n",
    "        print(f\"NOTE: Directory already exists for {media_id}, skipping unzip\")\n",
    "        continue\n",
    "        \n",
    "    # Create destination directory\n",
    "    os.makedirs(dst_path, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        # Extract directly to the media_id subfolder\n",
    "        print(f\"NOTE: Unzipping {zip_path} to {dst_path}\")\n",
    "        shutil.unpack_archive(zip_path, dst_path, 'zip')\n",
    "        \n",
    "        # Check if files were extracted to a subfolder with media_id name inside dst_path\n",
    "        # If so, move them up to dst_path\n",
    "        nested_dir = os.path.join(dst_path, media_id)\n",
    "        if os.path.exists(nested_dir) and os.path.isdir(nested_dir):\n",
    "            for item in os.listdir(nested_dir):\n",
    "                shutil.move(os.path.join(nested_dir, item), dst_path)\n",
    "            os.rmdir(nested_dir)  # Remove the now-empty nested directory\n",
    "    except Exception as e:\n",
    "        print(f\"WARNING: Issue with unpacking {media_id}: {str(e)}\")\n",
    "        continue\n",
    "    \n",
    "    # Check if the frames directory exists\n",
    "    frames_dir = os.path.join(dst_path, \"frames\")\n",
    "    frames_csv = os.path.join(dst_path, \"frames.csv\")\n",
    "    \n",
    "    if not os.path.exists(frames_dir):\n",
    "        print(f\"ERROR: Could not find frames directory for media {media_id} at {frames_dir}.\")\n",
    "        \n",
    "    if not os.path.exists(frames_csv):\n",
    "        print(f\"ERROR: Could not find frames.csv for media {media_id} at {frames_csv}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
