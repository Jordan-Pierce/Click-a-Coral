{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tator\n",
    "import panoptes_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_media(client, project, media_id, dataframe, set_active):\n",
    "    \"\"\"\n",
    "\n",
    "    :param client:\n",
    "    :param project:\n",
    "    :param media_id:\n",
    "    :param dataframe:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create subject set, link to project\n",
    "        subject_set = client.SubjectSet()\n",
    "        subject_set.links.project = project\n",
    "        subject_set.display_name = str(media_id)\n",
    "        subject_set.save()\n",
    "        \n",
    "        # Reload the project\n",
    "        project.reload()\n",
    "\n",
    "        # Convert the dataframe (frame paths) to a dict\n",
    "        subject_dict = dataframe.to_dict(orient='records')\n",
    "        # Create a new dictionary with 'Path' as keys and other values as values\n",
    "        subject_meta = {d['Path']: {k: v for k, v in d.items() if k != 'Path'} for d in subject_dict}\n",
    "\n",
    "        # Create subjects from the meta\n",
    "        subjects = []\n",
    "        subject_ids = []\n",
    "\n",
    "        # Loop through each of the frames and convert to a subject (creating a subject set)\n",
    "        for filename, metadata in tqdm(subject_meta.items()):\n",
    "            # Create the subject\n",
    "            subject = client.Subject()\n",
    "            # Link subject to project\n",
    "            subject.links.project = project\n",
    "            subject.add_location(filename)\n",
    "            # Update meta\n",
    "            subject.metadata.update(metadata)\n",
    "            # Save\n",
    "            subject.save()\n",
    "            # Append\n",
    "            subjects.append(subject)\n",
    "            subject_ids.append(subject.id)\n",
    "\n",
    "        # Add the list of subjects to set\n",
    "        subject_set.add(subjects)\n",
    "        # Save the subject set\n",
    "        subject_set.save()\n",
    "        project.save()\n",
    "\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"ERROR: Could not finish uploading subject set for {media_id} to Zooniverse.\\n{e}\")\n",
    "\n",
    "    if set_active:\n",
    "\n",
    "        try:\n",
    "            # Attaching the new subject set to all the active workflows\n",
    "            workflow_ids = project.__dict__['raw']['links']['active_workflows']\n",
    "\n",
    "            # If there are active workflows, link them to the next subject sets\n",
    "            for workflow_id in tqdm(workflow_ids):\n",
    "                # Create Workflow object\n",
    "                workflow = client.Workflow(workflow_id)\n",
    "                workflow_name = workflow.__dict__['raw']['display_name']\n",
    "                # Add the subject set created previously\n",
    "                print(f\"\\nNOTE: Adding subject set {subject_set.display_name} to workflow {workflow_name}\")\n",
    "                workflow.add_subject_sets([subject_set])\n",
    "                # Save\n",
    "                workflow.save()\n",
    "                project.save()\n",
    "\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"ERROR: Could not link media {media_id} to project workflows.\\n{e}\")\n",
    "\n",
    "    # Update the dataframe to now contain the subject IDs\n",
    "    # This is needed when downloading annotations later.\n",
    "    dataframe['Subject_ID'] = subject_ids\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = os.getenv('TATOR_TOKEN')\n",
    "project_id = 70\n",
    "\n",
    "try:\n",
    "    # Get the TATOR api given the provided token\n",
    "    api = tator.get_api(host='https://cloud.tator.io', token=token)\n",
    "    # Get the correct type of localization for the project (bounding box, attributes)\n",
    "    tator_project_id = project_id\n",
    "    state_type_id = 288  # State Type (ROV)\n",
    "    print(f\"NOTE: Authentication to TATOR successful for {api.whoami().username}\")\n",
    "except Exception as e:\n",
    "    raise Exception(f\"ERROR: Could not obtain needed information from TATOR.\\n{e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = os.getenv('ZOONIVERSE_USERNAME')\n",
    "password = os.getenv('ZOONIVERSE_PASSWORD')\n",
    "\n",
    "zoon_project_id = 21853\n",
    "\n",
    "try:\n",
    "    # Login to panoptes using username and password\n",
    "    panoptes_client.Panoptes.connect(username=username, password=password)\n",
    "    print(f\"NOTE: Authentication to Zooniverse successful for {username}\")\n",
    "except Exception as e:\n",
    "    raise Exception(f\"ERROR: Could not login to Panoptes for {username}\\n{e}\")\n",
    "\n",
    "try:\n",
    "    # Get access to the Zooniverse project given the provided credentials\n",
    "    project = panoptes_client.Project.find(id=zoon_project_id)\n",
    "    print(f\"NOTE: Connected to Zooniverse project '{project.title}' successfully\")\n",
    "except Exception as e:\n",
    "    raise Exception(f\"ERROR: Could not access project {zoon_project_id}.\\n{e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Needs Uploading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_ids = [\n",
    "    '13773236',\n",
    "    '13849318',\n",
    "    '13817345',\n",
    "    '14399481',\n",
    "    '17093804',\n",
    "    '14405503',\n",
    "    '13756556',\n",
    "    '17093860',\n",
    "    '13759791',\n",
    "    '13754339',\n",
    "    '17093861',\n",
    "    '17093864',\n",
    "    '13723028',\n",
    "    '13849916',\n",
    "    '13849706',\n",
    "    '14405003',\n",
    "    '13759171',\n",
    "    '14409485',\n",
    "    '13757674',\n",
    "    '13800889',\n",
    "    '13849803',\n",
    "    '17093852',\n",
    "    '13753671',\n",
    "    '17093859',\n",
    "    '17093853',\n",
    "    '17093842',\n",
    "    '13849372',\n",
    "    '14406510',\n",
    "    '17093839',\n",
    "    '14403746',\n",
    "    '13759653',\n",
    "    '13849299',\n",
    "    '14411239',\n",
    "    '13849343',\n",
    "    '13849727',\n",
    "    '13808161',\n",
    "    '17093740',\n",
    "    '17093879',\n",
    "    '14409735',\n",
    "    '13760111',\n",
    "    '13773515',\n",
    "    '17093892',\n",
    "    '13753944',\n",
    "    '14402741',\n",
    "    '13725519',\n",
    "    '14393472',\n",
    "    '14388418',\n",
    "    '13849672',\n",
    "    '13723943',\n",
    "    '14407606',\n",
    "    '14411903',\n",
    "    '14405002',\n",
    "    '13760355',\n",
    "    '17093826',\n",
    "    '14406760',\n",
    "    '13798701',\n",
    "    '17093847',\n",
    "    '13773086',\n",
    "    '17093870',\n",
    "    '13772881',\n",
    "    '13849797',\n",
    "    '14405754',\n",
    "    '13802769',\n",
    "    '14403247',\n",
    "    '13849687',\n",
    "    '14404072',\n",
    "    '17093770',\n",
    "    '17093766',\n",
    "    '13849370',\n",
    "    '17093817',\n",
    "    '17093857',\n",
    "    '13775472',\n",
    "    '14407856',\n",
    "    '17093755',\n",
    "    '14404702',\n",
    "    '13798999',\n",
    "    '17093831',\n",
    "    '13760124',\n",
    "    '14398477',\n",
    "    '13817627',\n",
    "    '17093814',\n",
    "    '13722070',\n",
    "    '14408480',\n",
    "    '14408730',\n",
    "    '13808199',\n",
    "    '13754680',\n",
    "    '13800998',\n",
    "    '17093793',\n",
    "    '14411489',\n",
    "    '13751248',\n",
    "    '13849670',\n",
    "    '14410740',\n",
    "    '13849222',\n",
    "    '14406305',\n",
    "    '14397224',\n",
    "    '17093858',\n",
    "    '13849720',\n",
    "    '14410349',\n",
    "    '17093760',\n",
    "    '13757903',\n",
    "    '14401993',\n",
    "    '14404451',\n",
    "    '13849697',\n",
    "    '14406259',\n",
    "    '13754287',\n",
    "    '11113559',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_path = os.path.abspath(\"../data/curated\")\n",
    "\n",
    "for media_id in media_ids:\n",
    "    # Assert that the zip file exists\n",
    "    zip_path = os.path.join(curated_path, f\"{media_id}.zip\")\n",
    "    if not os.path.exists(zip_path):\n",
    "        raise Exception(f\"ERROR: Could not find zip file for media {media_id} at {zip_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_path = os.path.abspath(\"../data/temp\")\n",
    "os.makedirs(temp_path, exist_ok=True)\n",
    "\n",
    "for media_id in media_ids:\n",
    "    # Unzip the media\n",
    "    zip_path = os.path.join(curated_path, f\"{media_id}.zip\")\n",
    "    dst_path = os.path.join(temp_path, media_id)\n",
    "    \n",
    "    # Check if zip exists and destination doesn't exist yet\n",
    "    if not os.path.exists(zip_path):\n",
    "        raise Exception(f\"ERROR: Could not find zip file for media {media_id} at {zip_path}.\")\n",
    "        \n",
    "    if os.path.exists(dst_path):\n",
    "        print(f\"NOTE: Directory already exists for {media_id}, skipping unzip\")\n",
    "        continue\n",
    "        \n",
    "    # Create destination directory\n",
    "    os.makedirs(dst_path, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        # Try to unpack the archive, handling empty zip files\n",
    "        print(f\"NOTE: Unzipping {zip_path} to {temp_path}\")\n",
    "        shutil.unpack_archive(zip_path, temp_path, 'zip')\n",
    "    except Exception as e:\n",
    "        print(f\"WARNING: Issue with unpacking {media_id}: {str(e)}\")\n",
    "        continue\n",
    "    \n",
    "    # Check if the frames directory exists\n",
    "    frames_dir = os.path.join(dst_path, \"frames\")\n",
    "    frames_csv = os.path.join(dst_path, \"frames.csv\")\n",
    "    \n",
    "    if not os.path.exists(frames_dir):\n",
    "        print(f\"ERROR: Could not find frames directory for media {media_id} at {frames_dir}.\")\n",
    "        \n",
    "    if not os.path.exists(frames_csv):\n",
    "        print(f\"ERROR: Could not find frames.csv for media {media_id} at {frames_csv}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for media_id in media_ids:\n",
    "    # Get the path to the frames directory and csv file\n",
    "    dst_path = os.path.join(temp_path, media_id)\n",
    "    frames_dir = os.path.join(dst_path, \"frames\")\n",
    "    frames_csv = os.path.join(dst_path, \"frames.csv\")\n",
    "\n",
    "    # Read the CSV file into a DataFrame\n",
    "    try:\n",
    "        df = pd.read_csv(frames_csv)\n",
    "        df['Path'] = [os.path.join(frames_dir, os.path.basename(filename)) for filename in df['Path']]\n",
    "        df.to_csv(frames_csv, index=False)\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Could not read CSV file for media {media_id} at {frames_csv}.\\n{e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for media_id in media_ids:\n",
    "    # Get the path to the frames directory and csv file\n",
    "    dst_path = os.path.join(temp_path, media_id)\n",
    "    frames_dir = os.path.join(dst_path, \"frames\")\n",
    "    frames_csv = os.path.join(dst_path, \"frames.csv\")\n",
    "\n",
    "    if not os.path.exists(frames_csv) or not os.path.exists(frames_dir):\n",
    "        print(f\"ERROR: Missing frames directory or CSV file for media {media_id}.\")\n",
    "        continue\n",
    "\n",
    "\n",
    "    # Upload the media to Zooniverse\n",
    "    try:\n",
    "        df = pd.read_csv(frames_csv)\n",
    "        upload_media(panoptes_client, project, media_id, df, set_active=True)\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Could not upload media {media_id} to Zooniverse.\\n{e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
